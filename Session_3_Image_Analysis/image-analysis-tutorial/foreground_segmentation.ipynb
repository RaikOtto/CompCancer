{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from skimage import io\n",
    "tf.executing_eagerly()\n",
    "\n",
    "np.random.seed(300)\n",
    "plt.rcParams['image.cmap'] = 'gist_earth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unet\n",
    "\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, n):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[n:] - cumsum[:-n]) / float(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # plot training and validation loss and binary accuracy\n",
    "    \n",
    "    loss = running_mean(history.history['loss'], 9)\n",
    "    val_loss = running_mean(history.history['val_loss'], 9)\n",
    "    #epochs = len(history.history['loss'])\n",
    "    epochs = len(loss)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.plot(range(0, epochs), loss , label='loss')\n",
    "    ax1.plot(range(0, epochs), val_loss, label='val_loss')\n",
    "    ax1.set_title('train and validation loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "    \n",
    "    acc = running_mean(history.history['binary_accuracy'], 9)\n",
    "    val_acc = running_mean(history.history['val_binary_accuracy'], 9)\n",
    "\n",
    "    ax2.plot(range(0, epochs), acc, label='binary_accuracy')\n",
    "    ax2.plot(range(0, epochs), val_acc, label='val_binary_accuracy')\n",
    "    ax2.set_title('train and validation binary accuracy')\n",
    "    ax2.legend(loc='lower right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(raw, gt, pred):\n",
    "    \n",
    "    thresh = 0.9\n",
    "    max_values = np.max(pred[:,0], axis=(1, 2))\n",
    "    if np.any(max_values < thresh):\n",
    "        print(\"Heads up: If prediction is below {} then the prediction map is shown.\".format(thresh))\n",
    "        print(\"Max predictions: {}\".format(max_values))\n",
    "    \n",
    "    num_samples = pred.shape[0]\n",
    "    fig, ax = plt.subplots(num_samples, 3, sharex=True, sharey=True, figsize=(12, num_samples * 4))\n",
    "    for i in range(num_samples):\n",
    "        ax[i, 0].imshow(raw[i,0], aspect=\"auto\")\n",
    "        ax[i, 1].imshow(gt[i,0], aspect=\"auto\")\n",
    "        # check for prediction threshold\n",
    "        if np.sum(max_values[i]) < thresh:\n",
    "            ax[i, 2].imshow(pred[i,0], aspect=\"auto\")\n",
    "        else:\n",
    "            ax[i, 2].imshow(pred[i,0] >= thresh, aspect=\"auto\")\n",
    "\n",
    "    ax[0, 0].set_title(\"Input\")\n",
    "    ax[0, 1].set_title(\"Ground truth\")\n",
    "    ax[0, 2].set_title(\"Prediction\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Load and visualize our toy data examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tif images and reformat the way keras requires it\n",
    "def load_dataset(in_folder):\n",
    "    x = []\n",
    "    y = []\n",
    "    raw_files = glob.glob(in_folder + '/raw_*.tif')\n",
    "    for raw_file in raw_files:\n",
    "        x.append(io.imread(raw_file))\n",
    "        y.append(io.imread(raw_file.replace('raw', 'gt')))\n",
    "    x = np.array(x)[:, np.newaxis]\n",
    "    y = np.array(y)[:, np.newaxis]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into train/val/test sets\n",
    "x_train, y_train = load_dataset('example_toy_data/train')\n",
    "x_val, y_val = load_dataset('example_toy_data/val')\n",
    "x_test, y_test = load_dataset('example_toy_data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show training examples\n",
    "num_samples = 3\n",
    "fig, ax = plt.subplots(num_samples, 2, sharey=True, figsize=(8, num_samples * 4))\n",
    "for i in range(num_samples):\n",
    "    ax[i, 0].imshow(x_train[i,0], aspect=\"auto\")\n",
    "    ax[i, 1].imshow(y_train[i,0], aspect=\"auto\")\n",
    "ax[0, 0].set_title(\"Input\")\n",
    "ax[0, 1].set_title(\"Ground truth\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Create and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input shape\n",
    "net_input = tf.keras.Input(shape=(1, 512, 512), name='img')\n",
    "\n",
    "# define activation function\n",
    "activation = tf.keras.layers.Activation(\"sigmoid\")\n",
    "\n",
    "# create unet with parameters: input, # output channel, unet depth, # fmaps\n",
    "net_output, receptive_field = unet.unet(net_input, 1, 2, 32, activation=activation)\n",
    "\n",
    "# instantiate the model\n",
    "net = tf.keras.Model(net_input, net_output, name='unet')\n",
    "\n",
    "# print network layers\n",
    "net.summary()\n",
    "print(\"Receptive field: \", receptive_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receptive Field of View\n",
    "\n",
    "The number of convolutions and the depth of the U-Net are the major factors in determining the \n",
    "receptive field of the network. The term is borrowed from biology where it describes the \"portion of sensory space that can elicit neuronal responses when stimulated\" (wikipedia). Each output pixel can look at/depends on an input patch with that diameter centered at its position.\n",
    "Based on this patch, the network has to be able to make a decision about the prediction for the respective pixel.\n",
    "Yet larger sizes increase the computation time significantly.\n",
    "\n",
    "The following code snippet visualizes the field of view of the center pixel for networks with varying depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randrange(len(x_train))\n",
    "out_channels = 1\n",
    "images = x_train[idx]\n",
    "rnd = random.randrange(len(images))\n",
    "image = images[rnd]\n",
    "#label = labels[rnd]\n",
    "\n",
    "net_input_t = tf.keras.Input(shape=(1, 512, 512), name='img')\n",
    "net_t = net_input_t\n",
    "#net_t = tf.keras.layers.ZeroPadding2D(12, data_format='channels_first')(net_input_t)\n",
    "fovs = []\n",
    "_, fov_tmp = unet.unet(net_t, out_channels, depth=1, num_fmaps=32)\n",
    "fovs.append(fov_tmp)\n",
    "_, fov_tmp = unet.unet(net_t, out_channels, depth=2, num_fmaps=32)\n",
    "fovs.append(fov_tmp)\n",
    "_, fov_tmp = unet.unet(net_t, out_channels, depth=3, num_fmaps=32)\n",
    "fovs.append(fov_tmp)\n",
    "_, fov_tmp = unet.unet(net_t, out_channels, depth=4, num_fmaps=32)\n",
    "fovs.append(fov_tmp)\n",
    "_, fov_tmp = unet.unet(net_t, out_channels, depth=5, num_fmaps=32)\n",
    "fovs.append(fov_tmp)\n",
    "\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "colors = [\"yellow\", \"red\", \"green\", \"blue\", \"magenta\"]\n",
    "plt.imshow(np.squeeze(image), cmap='gray')\n",
    "for idx, fov_t in enumerate(fovs):\n",
    "    print(\"Field of view at depth {}: {:3d} (color: {})\".format(idx+1, fov_t, colors[idx]))\n",
    "    xmin = image.shape[1]/2 - fov_t/2\n",
    "    xmax = image.shape[1]/2 + fov_t/2\n",
    "    ymin = image.shape[1]/2 - fov_t/2\n",
    "    ymax = image.shape[1]/2 + fov_t/2\n",
    "    plt.hlines(ymin, xmin, xmax, color=colors[idx], lw=3)\n",
    "    plt.hlines(ymax, xmin, xmax, color=colors[idx], lw=3)\n",
    "    plt.vlines(xmin, ymin, ymax, color=colors[idx], lw=3)\n",
    "    plt.vlines(xmax, ymin, ymax, color=colors[idx], lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the training configuration (optimizer, loss, metrics)\n",
    "net.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model, takes ~1:20min\n",
    "history = net.fit(x=x_train, y=y_train, batch_size=4, epochs=60, validation_data=(x_val, y_val))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss and accuracy\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Test and evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate our model performance on the test set\n",
    "results = net.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test set\n",
    "predictions = net.predict(x=x_test)\n",
    "\n",
    "# plot predicted results\n",
    "show_predictions(x_test, y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1: Continue training for more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# continue training, takes ~3min\n",
    "# heads up: the \"net\" variable still carries all the information from the previous training\n",
    "history_continued = net.fit(x=x_train, y=y_train, batch_size=4, epochs=160, validation_data=(x_val, y_val), \n",
    "                            initial_epoch=60)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append both histories\n",
    "for k in history.history.keys():\n",
    "    history.history[k] = history.history[k] + history_continued.history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss and accuracy\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate and predict test set\n",
    "results = net.evaluate(x=x_test, y=y_test)\n",
    "\n",
    "predictions = net.predict(x=x_test)\n",
    "show_predictions(x_test, y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The training of the networks depend on many hyperparameters such as\n",
    "- network architecture: #layers, #fmaps\n",
    "- batch size, learning rate\n",
    "- number and distribution of the training samples\n",
    "\n",
    "#### You can play and see how these settings influence the learning curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](example_learning_curves/lc_all.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2: Use early stopping to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping is on of keras callback functions which can be applied during training procedure\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define input shape, takes ~3min\n",
    "net_input = tf.keras.Input(shape=(1, 512, 512), name='img')\n",
    "\n",
    "# define activation function\n",
    "activation = tf.keras.layers.Activation(\"sigmoid\")\n",
    "\n",
    "# create unet with parameters: input, # output channel, unet depth, # fmaps\n",
    "net_output, receptive_field = unet.unet(net_input, 1, 2, 32, activation=activation)\n",
    "\n",
    "# redefine the model to overwrite previous trainings\n",
    "net_w_ea = tf.keras.Model(net_input, net_output, name='unet')\n",
    "\n",
    "# specify the training configuration (optimizer, loss, metrics)\n",
    "net_w_ea.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5)]\n",
    ")\n",
    "\n",
    "# specify early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30, restore_best_weights=True)\n",
    "history_w_ea = net_w_ea.fit(x=x_train, y=y_train, batch_size=4, epochs=500, validation_data=(x_val, y_val), \n",
    "                     callbacks=[es])\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss and accuracy\n",
    "plot_history(history_w_ea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate and predict test set\n",
    "results_w_ea = net_w_ea.evaluate(x=x_test, y=y_test)\n",
    "\n",
    "predictions_w_ea = net_w_ea.predict(x=x_test)\n",
    "show_predictions(x_test, y_test, predictions_w_ea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3: Use a data generator to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we have simulated data, we can use unlimited number of training examples\n",
    "# image generator copied from https://github.com/jakeret/tf_unet\n",
    "import image_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define image shape\n",
    "nx = 512\n",
    "ny = 512\n",
    "\n",
    "# create a wrapper generator which can be used in keras\n",
    "def train_generator(batch_size):\n",
    "    \n",
    "    # init image generator with the following parameters:\n",
    "    # nx, ny, cnt = 10, r_min = 5, r_max = 50, border = 92, sigma = 20, limit_num_samples = -1, binary = True\n",
    "    generator = image_gen.GrayScaleDataProvider(nx, ny, cnt=20, r_min=10, r_max=25, binary=True)\n",
    "    data_generator = image_gen.GrayScaleDataProvider(nx, ny, cnt=20, r_min=10, r_max=25, binary=True)\n",
    "    batch_labels = np.zeros((batch_size, 1)) \n",
    "    while True:\n",
    "        data, labels = data_generator(batch_size)\n",
    "        yield data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define input shape, takes ~3min\n",
    "net_input = tf.keras.Input(shape=(1, nx, ny), name='img')\n",
    "\n",
    "# define activation function\n",
    "activation = tf.keras.layers.Activation(\"sigmoid\")\n",
    "\n",
    "# create unet with parameters: input, # output channel, unet depth, # fmaps\n",
    "net_output, receptive_field = unet.unet(net_input, 1, 2, 32, activation=activation)\n",
    "\n",
    "# instantiate the model\n",
    "net_w_gen = tf.keras.Model(net_input, net_output, name='unet')\n",
    "\n",
    "net_w_gen.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5)]\n",
    ")\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30, restore_best_weights=True)\n",
    "\n",
    "# train the model by using the generator\n",
    "history_w_gen = net_w_gen.fit_generator(\n",
    "    generator=train_generator(4),\n",
    "    steps_per_epoch=4,\n",
    "    epochs=140,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[es]\n",
    ")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_w_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate and predict test set\n",
    "results_w_gen = net_w_gen.evaluate(x=x_test, y=y_test)\n",
    "\n",
    "predictions_w_gen = net_w_gen.predict(x=x_test)\n",
    "show_predictions(x_test, y_test, predictions_w_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_ws_image_analysis)",
   "language": "python",
   "name": "conda_ws_image_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
