{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Cancer Classification -- Minihackathon\n",
    "\n",
    "<img src=\"images/skin.jpg\" style=\"width: 256px;\">\n",
    "\n",
    "The Mini-Hackathon is based on work by Andre Esteva et al.\n",
    "\n",
    "In this script, you will be shown the ropes of transfer learning. First you train a model yourself. Thereafter, you will load the inception v3 model and retrain the model using the transfer-learned model.\n",
    "\n",
    "Afterwards you will be shown some options to modify your model even more via layer unfreezing and early stopping.\n",
    "You can skip the unfreezing and early stopage part, they serve the tutorial part of the hackathon.\n",
    "\n",
    "The aim of the hackathon is to create the model with highest classification efficiency.\n",
    "\n",
    "Notice that the images are complex and training times might be significant.\n",
    "\n",
    "The original challenge related to this Hackathon was [here](https://challenge.kitware.com/#phase/5840f53ccad3a51cc66c8dab),\n",
    "[Udacity's wrapper on the contest](https://github.com/udacity/dermatologist-ai) and here -->\n",
    "[Dasato](https://dasoto.github.io/skincancer/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Import modules \n",
    "\n",
    "Import InceptionV3: InceptionV2 model\n",
    "\n",
    "Dense, Dropout: CNN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### switch off deprecation and future warnings\n",
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit GPU Usage\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto() # Tensorflow 2.0 version\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries required for transfer learning\n",
    "# Before import any package, it's good to install it first using command such as conda install tensorflow or conda install tensorflow.\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input,decode_predictions\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.layers import Dense, GlobalAveragePooling2D,Dropout,Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Pre-process data, create image generator\n",
    " \n",
    "Create an image data generator using ImageDataGenerator class, the generator helps us to make it easy to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the dictionary for Image data Generator\n",
    "data_gen_args = dict(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True\n",
    ")\n",
    "\n",
    "# create two instances with the same arguments for train and test\n",
    "train_datagen = image.ImageDataGenerator(**data_gen_args)\n",
    "test_datagen = image.ImageDataGenerator(**data_gen_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data parsing\n",
    "\n",
    "Load the data using `flow_from_directory` method of data Generator, which takes the path to a directory, and generates batches of augmented/normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"Data_Minihackathon/train\",\n",
    "    target_size=(299,299),\n",
    "    batch_size=100\n",
    ")\n",
    "\n",
    "valid_generator = test_datagen.flow_from_directory(\n",
    "    \"Data_Minihackathon/valid\",\n",
    "    target_size=(299,299),\n",
    "    batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#take a look at one image\n",
    "z = plt.imread(\"Data_Minihackathon/test/melanoma/ISIC_0013766.jpg\")\n",
    "plt.imshow(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:  Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define your CNN model such as 3 convolutional layers with max pooling and 2 fully connected layers with dropout here:\n",
    "#  e.g. conv2d—>maxpooling—>conv2d—>maxpooling—>conv2d—>maxpooling—> dropout—>Flatten—>Dense—>Dropout—>Dense\n",
    "\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = 2, padding = 'same', activation = 'relu', input_shape = (299,299,3)))\n",
    "model.add(MaxPooling2D(pool_size=2,padding='same'))\n",
    "model.add(Conv2D(filters = 32, kernel_size = 2, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=2,padding='same'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = 2, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=2,padding='same'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hints: use model.complie function to compile your model\n",
    "# Recommended hyper-parameters: epochs=60, validation_steps=3\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include early stopping to avoid overfitting and save time\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "# Save the model with best weights, do create a model folder with mkdir saved_model\n",
    "checkpointer = ModelCheckpoint('saved_model/model.hdf5', verbose=1, save_best_only=True)\n",
    "# Stop the training if the model shows no improvement \n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=0, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training of initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model.fit_generator function to train your model\n",
    "import time\n",
    "start = time.time()\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch = 2,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=3, \n",
    "    epochs = 2, \n",
    "    verbose=1,\n",
    "   # callbacks=[checkpointer]\n",
    ")\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy will be mediocre, but how to improve it?\n",
    "\n",
    "One solution is to use transfer learning.\n",
    "\n",
    "## Step 5:  Transfer Learning\n",
    "\n",
    "# Load An InceptionV3 pre-trained model with InceptionV3 class of keras.applications module.\n",
    "\n",
    "Signature:\n",
    "\n",
    "keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000\n",
    ")\n",
    "\n",
    "Note that the default input image size for this model is 299x299.\n",
    "\n",
    "### Arguments\n",
    "    include_top: whether to include the fully-connected\n",
    "        layer at the top of the network.\n",
    "    weights: one of `None` (random initialization)\n",
    "        or 'imagenet' (pre-training on ImageNet).\n",
    "    input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "        to use as image input for the model.\n",
    "    input_shape: optional shape tuple, only to be specified\n",
    "        if `include_top` is False (otherwise the input shape\n",
    "        has to be `(299, 299, 3)` (with `channels_last` data format)\n",
    "        or `(3, 299, 299)` (with `channels_first` data format).\n",
    "        It should have exactly 3 inputs channels,\n",
    "        and width and height should be no smaller than 139.\n",
    "        E.g. `(150, 150, 3)` would be one valid value.\n",
    "    pooling: Optional pooling mode for feature extraction\n",
    "        when `include_top` is `False`.\n",
    "        - `None` means that the output of the model will be\n",
    "            the 4D tensor output of the\n",
    "            last convolutional layer.\n",
    "        - `avg` means that global average pooling\n",
    "            will be applied to the output of the\n",
    "            last convolutional layer, and thus\n",
    "            the output of the model will be a 2D tensor.\n",
    "        - `max` means that global max pooling will\n",
    "            be applied.\n",
    "    classes: optional number of classes to classify images\n",
    "        into, only to be specified if `include_top` is True, and\n",
    "        if no `weights` argument is specified.\n",
    "\n",
    "### Returns\n",
    "    A Keras model instance.\n",
    "\n",
    "Use the pre-trained feature extraction section of the InceptionV3  image classification model and learn classification layer\n",
    "\n",
    "To do:\n",
    "\n",
    "1. Get the output of InceptionV3, assuming you have loaded the pre-trained model at step2\n",
    "2. Define your model as the classifaction part\n",
    "3. Load the pre-trained weights from HDF5 file\n",
    "4. Freeze the original layers of pre-trained model(Inception3)\n",
    "5. Train the classification part with your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model  = InceptionV3(weights= 'imagenet', include_top=False)\n",
    "print('loaded model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the output of Inceptionv3\n",
    "# then input it to your classification part model\n",
    "# Define the output layers for Inceptionv3\n",
    "\n",
    "last = base_model.output\n",
    "x = GlobalAveragePooling2D()(last)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(3,activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input,outputs=preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading weights for your model Load weights via HDF5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the weights for the common layers from the benchmark model\n",
    "# Tips: use load_weights function of keras.applications.inception_v3.InceptionV3\n",
    "base_model.load_weights('saved_model/model.hdf5', by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the original layers of Inception3 and set the weights of feature extractor be untrainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "# Save the model with best weights\n",
    "checkpointer = ModelCheckpoint('saved_model/transfer_learning.hdf5', \n",
    "                               verbose=1,save_best_only=True)\n",
    "# Stop the traning if the model shows no improvement\n",
    "stopper = EarlyStopping(monitor='val_loss',min_delta=0.1,patience=1,\n",
    "                        verbose=1,mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history_transfer = model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch = 2,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=3, \n",
    "    epochs=2,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Display the dictionary of training metrics values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(history_transfer.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual finetuning via unfreezing classification layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you unfreeze\n",
    "\n",
    "for layer in model.layers[:197]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[197:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-compilation with different learning rate\n",
    "\n",
    "What happens if we slow down the learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import adam\n",
    "\n",
    "# use with slow learning rate and momentum to standard value\n",
    "model.compile(\n",
    "    optimizer=adam(lr=0.0001, beta_1=0.9, beta_2=0.999),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mode with best validation loss\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    \"saved_model/fine_tuning.hdf5\",\n",
    "    verbose = 1,\n",
    "    save_best_only = True,\n",
    "    monitor = \"val_loss\"\n",
    ")\n",
    "\n",
    "# Ensure that training stops if the validation loss does not improve\n",
    "\n",
    "stoptheshow = EarlyStopping(\n",
    "    monitor = 'val_loss, val_acc',\n",
    "    min_delta = 0.1,\n",
    "    patience = 2,\n",
    "    verbose = 1,\n",
    "    mode = 'auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=2,\n",
    "    validation_data = valid_generator,\n",
    "    validation_steps = 3,\n",
    "    epochs = 2,\n",
    "    verbose = 1,\n",
    "    callbacks = [checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7.1 : load the trained model\n",
    "model.load_weights('saved_model/fine_tuning.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon\n",
    "\n",
    "Now, train a model yourself to beat the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your source code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
