{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "#'  \n",
    "#' It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs,\n",
    "#' though it is still underfitting at that point.\n",
    "\n",
    "library(keras)\n",
    "#install_keras(tensorflow = \"gpu\")\n",
    "\n",
    "# Parameters --------------------------------------------------------------\n",
    "\n",
    "batch_size <- 32\n",
    "epochs <- 5\n",
    "data_augmentation <- TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation --------------------------------------------------------\n",
    "\n",
    "# See ?dataset_cifar10 for more info\n",
    "cifar10 <- dataset_cifar10()\n",
    "\n",
    "# Feature scale RGB values in test and train inputs  \n",
    "x_train <- cifar10$train$x/255\n",
    "x_test <- cifar10$test$x/255\n",
    "y_train <- to_categorical(cifar10$train$y, num_classes = 10)\n",
    "y_test <- to_categorical(cifar10$test$y, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Model ----------------------------------------------------------\n",
    "\n",
    "# Initialize sequential model\n",
    "model <- keras_model_sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model %>%\n",
    " \n",
    "  # Start with hidden 2D convolutional layer being fed 32x32 pixel images\n",
    "  layer_conv_2d(\n",
    "    filter = 32, kernel_size = c(3,3), padding = \"same\", \n",
    "    input_shape = c(32, 32, 3)\n",
    "  ) %>%\n",
    "  layer_activation(\"relu\") %>%\n",
    "\n",
    "  # Second hidden layer\n",
    "  layer_conv_2d(filter = 32, kernel_size = c(3,3)) %>%\n",
    "  layer_activation(\"relu\") %>%\n",
    "\n",
    "  # Use max pooling\n",
    "  layer_max_pooling_2d(pool_size = c(2,2)) %>%\n",
    "  layer_dropout(0.25) %>%\n",
    "  \n",
    "  # 2 additional hidden 2D convolutional layers\n",
    "  layer_conv_2d(filter = 32, kernel_size = c(3,3), padding = \"same\") %>%\n",
    "  layer_activation(\"relu\") %>%\n",
    "  layer_conv_2d(filter = 32, kernel_size = c(3,3)) %>%\n",
    "  layer_activation(\"relu\") %>%\n",
    "\n",
    "  # Use max pooling once more\n",
    "  layer_max_pooling_2d(pool_size = c(2,2)) %>%\n",
    "  layer_dropout(0.25) %>%\n",
    "  \n",
    "  # Flatten max filtered output into feature vector \n",
    "  # and feed into dense layer\n",
    "  layer_flatten() %>%\n",
    "  layer_dense(512) %>%\n",
    "  layer_activation(\"relu\") %>%\n",
    "  layer_dropout(0.5) %>%\n",
    "\n",
    "  # Outputs from dense layer are projected onto 10 unit output layer\n",
    "  layer_dense(10) %>%\n",
    "  layer_activation(\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set prediction performance measures\n",
    "opt <- optimizer_rmsprop(lr = 0.0001, decay = 1e-6)\n",
    "\n",
    "model %>% compile(\n",
    "  loss = \"categorical_crossentropy\",\n",
    "  optimizer = opt,\n",
    "  metrics = \"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'data_augmentation' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'data_augmentation' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Training ----------------------------------------------------------------\n",
    "\n",
    "if(!data_augmentation){\n",
    "  \n",
    "  model %>% fit(\n",
    "    x_train, y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = list(x_test, y_test),\n",
    "    shuffle = TRUE\n",
    "  )\n",
    "  \n",
    "} else {\n",
    "  \n",
    "  datagen <- image_data_generator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = TRUE\n",
    "  )\n",
    "  \n",
    "  datagen %>% fit_image_data_generator(x_train)\n",
    "  \n",
    "  model %>% fit_generator(\n",
    "    flow_images_from_data(x_train, y_train, datagen, batch_size = batch_size),\n",
    "    steps_per_epoch = as.integer(50000/batch_size), \n",
    "    epochs = epochs, \n",
    "    validation_data = list(x_test, y_test)\n",
    "  )\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
